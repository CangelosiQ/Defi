{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Défi Grosses Data 2018\n",
    "# Algorithme réseaux de neurones avec KERAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Annex' from '/home/marques/Documents/Projet_Meteo/Defi/Annex.py'>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from os import listdir\n",
    "import imp\n",
    "import Annex\n",
    "imp.reload(Annex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are addressing your request.\n",
      "Data has been imported. Size: (189280, 31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marques/Documents/Projet_Meteo/Defi/Annex.py:146: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df.mois[df.mois=='octobre']='10'\n",
      "/home/marques/Documents/Projet_Meteo/Defi/Annex.py:147: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df.mois[df.mois=='novembre']='11'\n",
      "/home/marques/Documents/Projet_Meteo/Defi/Annex.py:148: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df.mois[df.mois=='décembre']='12'\n",
      "/home/marques/Documents/Projet_Meteo/Defi/Annex.py:149: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df.mois=df.mois.astype('int')\n",
      "/home/marques/Documents/Projet_Meteo/Defi/Annex.py:150: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return df\n",
      "/home/marques/Documents/Projet_Meteo/Defi/Annex.py:151: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/marques/Documents/Projet_Meteo/Defi/Annex.py:152: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  def generate_submission_file(name, model, scale, fillna_method):\n",
      "/home/marques/Documents/Projet_Meteo/Defi/Annex.py:153: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_TEST=load_test_set()\n",
      "/home/marques/Documents/Projet_Meteo/Defi/Annex.py:154: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_TEST=convert_month_to_int(df_TEST)\n",
      "/home/marques/Documents/Projet_Meteo/Defi/Annex.py:155: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_dummies=pd.get_dummies(df_TEST[['insee']])\n",
      "/home/marques/Documents/Projet_Meteo/Defi/Annex.py:156: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_TEST_full_qtt=pd.concat([df_TEST,df_dummies],axis=1)\n",
      "/home/marques/Documents/Projet_Meteo/Defi/Annex.py:157: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if fillna_method==True:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Months converted to int.\n",
      "Dummies added.\n",
      "Date dropped.\n",
      "26528 data points deleted. 14.02 %\n",
      "Train size: 146476, Test size: 16276\n",
      "Data scaled\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,Y_train,Y_test,scaler=Annex.get_data_raw(scale=True, \n",
    "                                                        add_dummies=True,\n",
    "                                                        var_dummies=['insee','ddH10_rose4'],\n",
    "                                                        TrainTestSplit=True,\n",
    "                                                        sz_test=0.1,\n",
    "                                                        impute_method='drop',\n",
    "                                                        convert_month2int=True,\n",
    "                                                        date_method='drop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jeu de données imputé\n",
    "\n",
    "Mise au format numérique et centré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are addressing your request.\n",
      "Data has been imported. Size: (189280, 85)\n",
      "Train size: 170352, Test size: 18928\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-9262879c9723>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mX_test_imp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_imp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mX_train_imp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_imp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_imp,X_test_imp,Y_train_imp,Y_test_imp,scaler_imp=Annex.get_data_raw(scale=False, \n",
    "                                                        add_dummies=True,\n",
    "                                                        var_dummies=['insee','ddH10_rose4'],\n",
    "                                                        TrainTestSplit=True,\n",
    "                                                        sz_test=0.1,\n",
    "                                                        impute_method='imputed',\n",
    "                                                        convert_month2int=True,\n",
    "                                                        date_method='drop')\n",
    "\n",
    "X_train_imp.apply(pd.to_numeric, axis=1)\n",
    "X_test_imp.apply(pd.to_numeric, axis=1)\n",
    "\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train_imp)  \n",
    "X_train_imp = scaler.transform(X_train_imp)  \n",
    "X_test_imp = scaler.transform(X_test_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réseau de neurones avec Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.2\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,SimpleRNN, Lambda,GRU,AveragePooling1D\n",
    "from keras.layers import Conv2D, MaxPooling2D,LSTM,LocallyConnected2D,Convolution2D,Reshape,Conv1D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import RMSprop,Nadam,Adam,SGD\n",
    "from keras import backend as K\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des séquences du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    #model.add(Conv1D(50,input_dim=38, kernel_size=3))\n",
    "    model.add(Dense(80, input_dim=38, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(80, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.05))\n",
    "    model.add(Dense(80, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.05))\n",
    "    model.add(Dense(80, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146476, 38)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " \n",
    "def baseline_model():  \n",
    "    # create model  \n",
    "    model = Sequential()  \n",
    "    #model.add(Conv1D(filters=10,kernel_size=3,border_mode='valid', input_shape=(None,38)))\n",
    "    model.add(Dense(200, input_shape=(38,),kernel_initializer='normal', activation='relu'))\n",
    "    #model.add(Conv1D(50,kernel_size=3,strides=1))\n",
    "    model.add(SimpleRNN(units=30))\n",
    "    model.add(Dense(200, kernel_initializer='normal', activation='relu'))  \n",
    "    model.add(Dense(1, kernel_initializer='normal'))  \n",
    "    # Compile model  \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')  \n",
    "    return model   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Modèles qui ont donné de bons résultats (1.17) \n",
    "\n",
    "Ce modèle là, quitte à ajouter une couche dense de 100 neurones.\n",
    "Attention, en fonction du jeu de données de départ (imputé ou pas), régler la taille de la couche d'entrée. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def baseline_model():    \n",
    "    # create model  \n",
    "    model = Sequential()  \n",
    "    model.add(Dense(200, input_shape=(38,), kernel_initializer='normal', activation='relu'))  \n",
    "    model.add(Dense(200, kernel_initializer='normal', activation='relu'),) \n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))  \n",
    "    # Compile model  \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')  \n",
    "    return model  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construction du modèle et estimation sur échantillon test (pas de validation croisée pour l'instant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_conv=np.expand_dims(X_train, axis=0)\n",
    "X_train_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "\n",
    "nb_epoch=30\n",
    "batch_size=15\n",
    "\n",
    "ts = time.time()\n",
    "nnet = KerasRegressor(build_fn=baseline_model, epochs=nb_epoch, batch_size=batch_size, verbose=1)\n",
    "\n",
    "nnet.fit(X_train,Y_train)\n",
    "score = nnet.score(X_test, Y_test)\n",
    "ypred = nnet.predict(X_test)\n",
    "te = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 1.011370, time running : 497 secondes\n"
     ]
    }
   ],
   "source": [
    "print(\"Score : %f, time running : %d secondes\" %(score, te-ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation croisée sur les paramètres du réseau de neurones\n",
    "\n",
    "Optimisation du nombre d'époques\n",
    "\n",
    "##### Question : pourquoi le nombre d'époque est toujours à 10 ? (Même si on change le paramètre ?)\n",
    "\n",
    "A FAIRE : \n",
    "- changer l'optimizer (dans baseline_model1 : tester sgd \n",
    "##### Moins bon que adam\n",
    "- tester la convolution en 1D pour le temps (pour cela, rajouter une ou plusieurs variables sur la date)\n",
    "- optimiser la taille du batch (augmenter ?)\n",
    "- optimiser si possible les paramètres du baseline_model (ex : elu au lieu de relu pour fonction d'activation)\n",
    "- tester avec echantillons avec complétion de NAs\n",
    "- tester cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "param_grid=[{\"batch_size\":[25,40]}]\n",
    "nnet=GridSearchCV(KerasRegressor(build_fn=baseline_model, verbose=1),param_grid,cv=5,n_jobs=-1)\n",
    "nnet.fit(X_train,Y_train, epochs=1)\n",
    "score = nnet.score(X_test, Y_test)\n",
    "ypred = nnet.predict(X_test)\n",
    "te = time.time()\n",
    "t_total = te-ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nnet.best_params_[\"nb_epoch\"]\n",
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" % (nnet.best_score_,nnet.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autres essais "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "117180/117180 [==============================] - 9s - loss: 2.3663     \n",
      "Epoch 2/30\n",
      "117180/117180 [==============================] - 9s - loss: 1.4698     \n",
      "Epoch 3/30\n",
      "117180/117180 [==============================] - 11s - loss: 1.3754    \n",
      "Epoch 4/30\n",
      "117180/117180 [==============================] - 11s - loss: 1.3098    \n",
      "Epoch 5/30\n",
      "117180/117180 [==============================] - 12s - loss: 1.2721    \n",
      "Epoch 6/30\n",
      "117180/117180 [==============================] - 11s - loss: 1.2337    \n",
      "Epoch 7/30\n",
      "117180/117180 [==============================] - 12s - loss: 1.2123    \n",
      "Epoch 8/30\n",
      "117180/117180 [==============================] - 11s - loss: 1.1909    \n",
      "Epoch 9/30\n",
      "117180/117180 [==============================] - 11s - loss: 1.1712    \n",
      "Epoch 10/30\n",
      "117180/117180 [==============================] - 12s - loss: 1.1469    \n",
      "Epoch 11/30\n",
      "117180/117180 [==============================] - 12s - loss: 1.1333    \n",
      "Epoch 12/30\n",
      "117180/117180 [==============================] - 12s - loss: 1.1189    \n",
      "Epoch 13/30\n",
      "117180/117180 [==============================] - 13s - loss: 1.1009    \n",
      "Epoch 14/30\n",
      "117180/117180 [==============================] - 13s - loss: 1.0885    \n",
      "Epoch 15/30\n",
      "117180/117180 [==============================] - 13s - loss: 1.0731    \n",
      "Epoch 16/30\n",
      "117180/117180 [==============================] - 13s - loss: 1.0591    \n",
      "Epoch 17/30\n",
      "117180/117180 [==============================] - 13s - loss: 1.0494    \n",
      "Epoch 18/30\n",
      "117180/117180 [==============================] - 13s - loss: 1.0368    \n",
      "Epoch 19/30\n",
      "117180/117180 [==============================] - 12s - loss: 1.0242    \n",
      "Epoch 20/30\n",
      "117180/117180 [==============================] - 15s - loss: 1.0148    \n",
      "Epoch 21/30\n",
      "117180/117180 [==============================] - 15s - loss: 1.0033    \n",
      "Epoch 22/30\n",
      "117180/117180 [==============================] - 15s - loss: 0.9934    \n",
      "Epoch 23/30\n",
      "117180/117180 [==============================] - 15s - loss: 0.9860    \n",
      "Epoch 24/30\n",
      "117180/117180 [==============================] - 14s - loss: 0.9784    \n",
      "Epoch 25/30\n",
      "117180/117180 [==============================] - 16s - loss: 0.9663    \n",
      "Epoch 26/30\n",
      "117180/117180 [==============================] - 15s - loss: 0.9590    \n",
      "Epoch 27/30\n",
      "117180/117180 [==============================] - 14s - loss: 0.9525    \n",
      "Epoch 28/30\n",
      "117180/117180 [==============================] - 14s - loss: 0.9430    \n",
      "Epoch 29/30\n",
      "117180/117180 [==============================] - 13s - loss: 0.9362    \n",
      "Epoch 30/30\n",
      "117180/117180 [==============================] - 13s - loss: 0.9294    \n",
      "28410/29296 [============================>.] - ETA: 0sEpoch 1/30\n",
      "117181/117181 [==============================] - 9s - loss: 2.3904     \n",
      "Epoch 2/30\n",
      "117181/117181 [==============================] - 11s - loss: 1.4572    \n",
      "Epoch 3/30\n",
      "117181/117181 [==============================] - 11s - loss: 1.3718    \n",
      "Epoch 4/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.3165    \n",
      "Epoch 5/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.2776    \n",
      "Epoch 6/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.2476    \n",
      "Epoch 7/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.2198    \n",
      "Epoch 8/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.1928    \n",
      "Epoch 9/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.1744    \n",
      "Epoch 10/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.1473    \n",
      "Epoch 11/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.1338    \n",
      "Epoch 12/30\n",
      "117181/117181 [==============================] - 13s - loss: 1.1113    \n",
      "Epoch 13/30\n",
      "117181/117181 [==============================] - 13s - loss: 1.0985    \n",
      "Epoch 14/30\n",
      "117181/117181 [==============================] - 15s - loss: 1.0890    \n",
      "Epoch 15/30\n",
      "117181/117181 [==============================] - 15s - loss: 1.0751    \n",
      "Epoch 16/30\n",
      "117181/117181 [==============================] - 15s - loss: 1.0585    \n",
      "Epoch 17/30\n",
      "117181/117181 [==============================] - 15s - loss: 1.0476    \n",
      "Epoch 18/30\n",
      "117181/117181 [==============================] - 16s - loss: 1.0361    \n",
      "Epoch 19/30\n",
      "117181/117181 [==============================] - 16s - loss: 1.0239    \n",
      "Epoch 20/30\n",
      "117181/117181 [==============================] - 16s - loss: 1.0146    \n",
      "Epoch 21/30\n",
      "117181/117181 [==============================] - 16s - loss: 1.0086    \n",
      "Epoch 22/30\n",
      "117181/117181 [==============================] - 14s - loss: 0.9954    \n",
      "Epoch 23/30\n",
      "117181/117181 [==============================] - 14s - loss: 0.9907    \n",
      "Epoch 24/30\n",
      "117181/117181 [==============================] - 14s - loss: 0.9794    \n",
      "Epoch 25/30\n",
      "117181/117181 [==============================] - 12s - loss: 0.9734    \n",
      "Epoch 26/30\n",
      "117181/117181 [==============================] - 12s - loss: 0.9618    \n",
      "Epoch 27/30\n",
      "117181/117181 [==============================] - 12s - loss: 0.9573    \n",
      "Epoch 28/30\n",
      "117181/117181 [==============================] - 12s - loss: 0.9521    \n",
      "Epoch 29/30\n",
      "117181/117181 [==============================] - 12s - loss: 0.9462    \n",
      "Epoch 30/30\n",
      "117181/117181 [==============================] - 12s - loss: 0.9376    \n",
      "28575/29295 [============================>.] - ETA: 0sEpoch 1/30\n",
      "117181/117181 [==============================] - 9s - loss: 2.3933     \n",
      "Epoch 2/30\n",
      "117181/117181 [==============================] - 10s - loss: 1.4625    \n",
      "Epoch 3/30\n",
      "117181/117181 [==============================] - 11s - loss: 1.3779    \n",
      "Epoch 4/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.3166    \n",
      "Epoch 5/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.2798    \n",
      "Epoch 6/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.2494    \n",
      "Epoch 7/30\n",
      "117181/117181 [==============================] - 11s - loss: 1.2186    \n",
      "Epoch 8/30\n",
      "117181/117181 [==============================] - 11s - loss: 1.1987    \n",
      "Epoch 9/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.1767    \n",
      "Epoch 10/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.1576    \n",
      "Epoch 11/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.1428    \n",
      "Epoch 12/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.1280    \n",
      "Epoch 13/30\n",
      "117181/117181 [==============================] - 14s - loss: 1.1165    \n",
      "Epoch 14/30\n",
      "117181/117181 [==============================] - 14s - loss: 1.0982    \n",
      "Epoch 15/30\n",
      "117181/117181 [==============================] - 15s - loss: 1.0830    \n",
      "Epoch 16/30\n",
      "117181/117181 [==============================] - 14s - loss: 1.0744    \n",
      "Epoch 17/30\n",
      "117181/117181 [==============================] - 11s - loss: 1.0600    \n",
      "Epoch 18/30\n",
      "117181/117181 [==============================] - 11s - loss: 1.0496    \n",
      "Epoch 19/30\n",
      "117181/117181 [==============================] - 11s - loss: 1.0374    \n",
      "Epoch 20/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.0287    \n",
      "Epoch 21/30\n",
      "117181/117181 [==============================] - 13s - loss: 1.0192    \n",
      "Epoch 22/30\n",
      "117181/117181 [==============================] - 11s - loss: 1.0109    \n",
      "Epoch 23/30\n",
      "117181/117181 [==============================] - 15s - loss: 1.0019    \n",
      "Epoch 24/30\n",
      "117181/117181 [==============================] - 16s - loss: 0.9967    \n",
      "Epoch 25/30\n",
      "117181/117181 [==============================] - 16s - loss: 0.9885    \n",
      "Epoch 26/30\n",
      "117181/117181 [==============================] - 14s - loss: 0.9816    \n",
      "Epoch 27/30\n",
      "117181/117181 [==============================] - 13s - loss: 0.9720    \n",
      "Epoch 28/30\n",
      "117181/117181 [==============================] - 15s - loss: 0.9683    \n",
      "Epoch 29/30\n",
      "117181/117181 [==============================] - 13s - loss: 0.9584    \n",
      "Epoch 30/30\n",
      "117181/117181 [==============================] - 14s - loss: 0.9556    \n",
      "28140/29295 [===========================>..] - ETA: 0sEpoch 1/30\n",
      "117181/117181 [==============================] - 9s - loss: 2.3171     \n",
      "Epoch 2/30\n",
      "117181/117181 [==============================] - 10s - loss: 1.4450    \n",
      "Epoch 3/30\n",
      "117181/117181 [==============================] - 13s - loss: 1.3602    \n",
      "Epoch 4/30\n",
      "117181/117181 [==============================] - 13s - loss: 1.3075    \n",
      "Epoch 5/30\n",
      "117181/117181 [==============================] - 15s - loss: 1.2631    \n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117181/117181 [==============================] - 13s - loss: 1.2334    \n",
      "Epoch 7/30\n",
      "117181/117181 [==============================] - 13s - loss: 1.2047    \n",
      "Epoch 8/30\n",
      "117181/117181 [==============================] - 13s - loss: 1.1847    \n",
      "Epoch 9/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.1646    \n",
      "Epoch 10/30\n",
      "117181/117181 [==============================] - 11s - loss: 1.1412    \n",
      "Epoch 11/30\n",
      "117181/117181 [==============================] - 11s - loss: 1.1217    \n",
      "Epoch 12/30\n",
      "117181/117181 [==============================] - 11s - loss: 1.1072    \n",
      "Epoch 13/30\n",
      "117181/117181 [==============================] - 14s - loss: 1.0898    \n",
      "Epoch 14/30\n",
      "117181/117181 [==============================] - 17s - loss: 1.0790    \n",
      "Epoch 15/30\n",
      "117181/117181 [==============================] - 14s - loss: 1.0658    \n",
      "Epoch 16/30\n",
      "117181/117181 [==============================] - 15s - loss: 1.0524    \n",
      "Epoch 17/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.0384    \n",
      "Epoch 18/30\n",
      "117181/117181 [==============================] - 17s - loss: 1.0268    \n",
      "Epoch 19/30\n",
      "117181/117181 [==============================] - 15s - loss: 1.0161    \n",
      "Epoch 20/30\n",
      "117181/117181 [==============================] - 13s - loss: 1.0088    \n",
      "Epoch 21/30\n",
      "117181/117181 [==============================] - 12s - loss: 0.9992    \n",
      "Epoch 22/30\n",
      "117181/117181 [==============================] - 12s - loss: 0.9928    \n",
      "Epoch 23/30\n",
      "117181/117181 [==============================] - 12s - loss: 0.9793    \n",
      "Epoch 24/30\n",
      "117181/117181 [==============================] - 13s - loss: 0.9726    \n",
      "Epoch 25/30\n",
      "117181/117181 [==============================] - 13s - loss: 0.9642    \n",
      "Epoch 26/30\n",
      "117181/117181 [==============================] - 16s - loss: 0.9600    \n",
      "Epoch 27/30\n",
      "117181/117181 [==============================] - 16s - loss: 0.9543    \n",
      "Epoch 28/30\n",
      "117181/117181 [==============================] - 16s - loss: 0.9490    \n",
      "Epoch 29/30\n",
      "117181/117181 [==============================] - 15s - loss: 0.9395    \n",
      "Epoch 30/30\n",
      "117181/117181 [==============================] - 16s - loss: 0.9357    \n",
      "28725/29295 [============================>.] - ETA: 0sEpoch 1/30\n",
      "117181/117181 [==============================] - 9s - loss: 2.3267     \n",
      "Epoch 2/30\n",
      "117181/117181 [==============================] - 9s - loss: 1.4514     \n",
      "Epoch 3/30\n",
      "117181/117181 [==============================] - 10s - loss: 1.3605    \n",
      "Epoch 4/30\n",
      "117181/117181 [==============================] - 11s - loss: 1.3121    \n",
      "Epoch 5/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.2687    \n",
      "Epoch 6/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.2374    \n",
      "Epoch 7/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.2100    \n",
      "Epoch 8/30\n",
      "117181/117181 [==============================] - 13s - loss: 1.1881    \n",
      "Epoch 9/30\n",
      "117181/117181 [==============================] - 14s - loss: 1.1666    \n",
      "Epoch 10/30\n",
      "117181/117181 [==============================] - 15s - loss: 1.1402    \n",
      "Epoch 11/30\n",
      "117181/117181 [==============================] - 14s - loss: 1.1222    \n",
      "Epoch 12/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.1085    \n",
      "Epoch 13/30\n",
      "117181/117181 [==============================] - 15s - loss: 1.0930    \n",
      "Epoch 14/30\n",
      "117181/117181 [==============================] - 16s - loss: 1.0762    \n",
      "Epoch 15/30\n",
      "117181/117181 [==============================] - 16s - loss: 1.0646    \n",
      "Epoch 16/30\n",
      "117181/117181 [==============================] - 16s - loss: 1.0474    \n",
      "Epoch 17/30\n",
      "117181/117181 [==============================] - 15s - loss: 1.0364    \n",
      "Epoch 18/30\n",
      "117181/117181 [==============================] - 15s - loss: 1.0264    \n",
      "Epoch 19/30\n",
      "117181/117181 [==============================] - 14s - loss: 1.0197    \n",
      "Epoch 20/30\n",
      "117181/117181 [==============================] - 13s - loss: 1.0082    \n",
      "Epoch 21/30\n",
      "117181/117181 [==============================] - 16s - loss: 0.9972    \n",
      "Epoch 22/30\n",
      "117181/117181 [==============================] - 17s - loss: 0.9918    \n",
      "Epoch 23/30\n",
      "117181/117181 [==============================] - 16s - loss: 0.9800    \n",
      "Epoch 24/30\n",
      "117181/117181 [==============================] - 16s - loss: 0.9703    \n",
      "Epoch 25/30\n",
      "117181/117181 [==============================] - 16s - loss: 0.9647    \n",
      "Epoch 26/30\n",
      "117181/117181 [==============================] - 17s - loss: 0.9565    \n",
      "Epoch 27/30\n",
      "117181/117181 [==============================] - 15s - loss: 0.9478    \n",
      "Epoch 28/30\n",
      "117181/117181 [==============================] - 12s - loss: 0.9443    \n",
      "Epoch 29/30\n",
      "117181/117181 [==============================] - 13s - loss: 0.9391    \n",
      "Epoch 30/30\n",
      "117181/117181 [==============================] - 13s - loss: 0.9319    \n",
      "29190/29295 [============================>.] - ETA: 0sResults: 1.09 (0.01) MSE ; time running : 2051 secondes\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, random_state=seed)\n",
    "\n",
    "ts = time.time()\n",
    "results = cross_val_score(nnet, X_train, Y_train, cv=kfold)\n",
    "te = time.time()\n",
    "\n",
    "print(\"Results: %.2f (%.2f) MSE ; time running : %d secondes\" % (results.mean(), results.std(),te-ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Months converted to int.\n",
      "Dummies added.\n",
      "Date dropped.\n",
      "20595/21168 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'File ./../data_meteo/submission_13dec2017_15h00_rnnkeras.csv generated.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Annex.generate_submission_file(\"submission_13dec2017_15h00_rnnkeras.csv\", nnet, scaler, add_dummies=True, var_dummies=['insee','ddH10_rose4'], \n",
    "                         convert_month2int=True, date_method='drop', fillna_method='zeros' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
