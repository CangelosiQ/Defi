{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Défi Grosses Data 2018\n",
    "# Algorithme réseaux de neurones avec KERAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Annex' from '/home/marques/Documents/Projet_Meteo/Defi/Annex.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from os import listdir\n",
    "import imp\n",
    "import Annex\n",
    "imp.reload(Annex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are addressing your request.\n",
      "Data has been imported. Size: (189280, 31)\n",
      "Months converted to int.\n",
      "Dummies added.\n",
      "Date transformed in a projection of the week number on a circle.\n",
      "26528 data points deleted. 14.02 %\n",
      "Train size: 146476, Test size: 16276\n",
      "Data scaled\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,Y_train,Y_test,X,Y,scaler=Annex.get_data_raw(scale=True, \n",
    "                                                        add_dummies=True,\n",
    "                                                        var_dummies=['insee','ddH10_rose4'],\n",
    "                                                        TrainTestSplit=True,\n",
    "                                                        sz_test=0.1,\n",
    "                                                        impute_method='drop',\n",
    "                                                        convert_month2int=True,\n",
    "                                                        date_method='week_circle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jeu de données imputé\n",
    "\n",
    "Mise au format numérique et centré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imp,X_test_imp,Y_train_imp,Y_test_imp,X_imp, Y_imp,scaler_imp=Annex.get_data_raw(scale=False, \n",
    "                                                        add_dummies=True,\n",
    "                                                        var_dummies=['insee','ddH10_rose4'],\n",
    "                                                        TrainTestSplit=True,\n",
    "                                                        sz_test=0.1,\n",
    "                                                        impute_method='imputed',\n",
    "                                                        convert_month2int=True,\n",
    "                                                        date_method='drop')\n",
    "\n",
    "X_train_imp.apply(pd.to_numeric, axis=1)\n",
    "X_test_imp.apply(pd.to_numeric, axis=1)\n",
    "\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train_imp)  \n",
    "X_train_imp = scaler.transform(X_train_imp)  \n",
    "X_test_imp = scaler.transform(X_test_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réseau de neurones avec Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.5\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,SimpleRNN, Lambda,GRU,AveragePooling1D\n",
    "from keras.layers import Conv2D, MaxPooling2D,LSTM,LocallyConnected2D,Convolution2D,Reshape,Conv1D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import RMSprop,Nadam,Adam,SGD\n",
    "from keras import backend as K\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Définition des séquences du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 80)                3120      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 80)                6480      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 80)                6480      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 80)                6480      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 81        \n",
      "=================================================================\n",
      "Total params: 22,641\n",
      "Trainable params: 22,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    #model.add(Conv1D(50,input_dim=38, kernel_size=3))\n",
    "    model.add(Dense(80, input_dim=38, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(80, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.05))\n",
    "    model.add(Dense(80, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.05))\n",
    "    model.add(Dense(80, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "baseline_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146476, 40)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():  \n",
    "    # create model  \n",
    "    model = Sequential()  \n",
    "    #model.add(Conv1D(filters=10,kernel_size=3,border_mode='valid', input_shape=(None,38)))\n",
    "    model.add(Dense(200, input_shape=(40,),kernel_initializer='normal', activation='relu'))\n",
    "    #model.add(Conv1D(50,kernel_size=3,strides=1))\n",
    "    model.add(SimpleRNN(units=30))\n",
    "    model.add(Dense(200, kernel_initializer='normal', activation='relu'))  \n",
    "    model.add(Dense(1, kernel_initializer='normal'))  \n",
    "    # Compile model  \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')  \n",
    "    return model\n",
    "\n",
    "#baseline_model().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Modèles qui ont donné de bons résultats (1.17) \n",
    "\n",
    "Ce modèle là, quitte à ajouter une couche dense de 100 neurones.\n",
    "Attention, en fonction du jeu de données de départ (imputé ou pas), régler la taille de la couche d'entrée. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 200)               8200      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 48,601\n",
      "Trainable params: 48,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def baseline_model():    \n",
    "    # create model  \n",
    "    model = Sequential()  \n",
    "    model.add(Dense(200, input_shape=(40,), kernel_initializer='normal', activation='relu'))  \n",
    "    model.add(Dense(200, kernel_initializer='normal', activation='relu'),) \n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))  \n",
    "    # Compile model  \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')  \n",
    "    return model   \n",
    "\n",
    "baseline_model().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construction du modèle et estimation sur échantillon test (pas de validation croisée pour l'instant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 146476, 40)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_conv=np.expand_dims(X_train, axis=0)\n",
    "X_train_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 146476 samples, validate on 16276 samples\n",
      "Epoch 1/30\n",
      "146476/146476 [==============================] - 18s - loss: 2.1541 - val_loss: 1.4370\n",
      "Epoch 2/30\n",
      "146476/146476 [==============================] - 19s - loss: 1.4045 - val_loss: 1.2760\n",
      "Epoch 3/30\n",
      "146476/146476 [==============================] - 19s - loss: 1.3160 - val_loss: 1.6040\n",
      "Epoch 4/30\n",
      "146476/146476 [==============================] - 19s - loss: 1.2600 - val_loss: 1.1751\n",
      "Epoch 5/30\n",
      "146476/146476 [==============================] - 19s - loss: 1.2199 - val_loss: 1.1482\n",
      "Epoch 6/30\n",
      "146476/146476 [==============================] - 19s - loss: 1.1833 - val_loss: 1.1635\n",
      "Epoch 7/30\n",
      "146476/146476 [==============================] - 19s - loss: 1.1595 - val_loss: 1.1233\n",
      "Epoch 8/30\n",
      "146476/146476 [==============================] - 19s - loss: 1.1351 - val_loss: 1.1848\n",
      "Epoch 9/30\n",
      "146476/146476 [==============================] - 19s - loss: 1.1159 - val_loss: 1.1255\n",
      "Epoch 10/30\n",
      "146476/146476 [==============================] - 19s - loss: 1.0967 - val_loss: 1.0615\n",
      "Epoch 11/30\n",
      "146476/146476 [==============================] - 19s - loss: 1.0797 - val_loss: 1.1031\n",
      "Epoch 12/30\n",
      "146476/146476 [==============================] - 20s - loss: 1.0651 - val_loss: 1.0750\n",
      "Epoch 13/30\n",
      "146476/146476 [==============================] - 19s - loss: 1.0510 - val_loss: 1.0579\n",
      "Epoch 14/30\n",
      "146476/146476 [==============================] - 19s - loss: 1.0384 - val_loss: 1.0580\n",
      "Epoch 15/30\n",
      "146476/146476 [==============================] - 19s - loss: 1.0237 - val_loss: 1.0701\n",
      "Epoch 16/30\n",
      "146476/146476 [==============================] - 19s - loss: 1.0101 - val_loss: 1.0410\n",
      "Epoch 17/30\n",
      "146476/146476 [==============================] - 20s - loss: 1.0031 - val_loss: 1.0412\n",
      "Epoch 18/30\n",
      "146476/146476 [==============================] - 19s - loss: 0.9917 - val_loss: 1.0402\n",
      "Epoch 19/30\n",
      "146476/146476 [==============================] - 20s - loss: 0.9841 - val_loss: 1.0325\n",
      "Epoch 20/30\n",
      "146476/146476 [==============================] - 19s - loss: 0.9757 - val_loss: 1.0301\n",
      "Epoch 21/30\n",
      "146476/146476 [==============================] - 20s - loss: 0.9663 - val_loss: 1.0904\n",
      "Epoch 22/30\n",
      "146476/146476 [==============================] - 19s - loss: 0.9618 - val_loss: 1.0261\n",
      "Epoch 23/30\n",
      "146476/146476 [==============================] - 19s - loss: 0.9509 - val_loss: 1.0128\n",
      "Epoch 24/30\n",
      "146476/146476 [==============================] - 18s - loss: 0.9467 - val_loss: 1.0051\n",
      "Epoch 25/30\n",
      "146476/146476 [==============================] - 18s - loss: 0.9381 - val_loss: 1.0229\n",
      "Epoch 26/30\n",
      "146476/146476 [==============================] - 18s - loss: 0.9350 - val_loss: 1.0197\n",
      "Epoch 27/30\n",
      "146476/146476 [==============================] - 18s - loss: 0.9289 - val_loss: 1.0130\n",
      "Epoch 28/30\n",
      "146476/146476 [==============================] - 18s - loss: 0.9222 - val_loss: 1.0107\n",
      "Epoch 29/30\n",
      "146476/146476 [==============================] - 18s - loss: 0.9190 - val_loss: 1.0175\n",
      "Epoch 30/30\n",
      "146476/146476 [==============================] - 19s - loss: 0.9125 - val_loss: 0.9815\n",
      "15870/16276 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "\n",
    "nb_epoch=30\n",
    "batch_size=15\n",
    "\n",
    "ts = time.time()\n",
    "nnet = KerasRegressor(build_fn=baseline_model, epochs=nb_epoch, batch_size=batch_size, verbose=1)\n",
    "\n",
    "nnet.fit(X_train,Y_train,\n",
    "         epochs=nb_epoch,\n",
    "         batch_size=batch_size,\n",
    "         validation_data=(X_test, Y_test))\n",
    "score = nnet.score(X_test, Y_test)\n",
    "ypred = nnet.predict(X_test)\n",
    "te = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score : 0.981487, time running : 584 secondes\n"
     ]
    }
   ],
   "source": [
    "print(\"Score : %f, time running : %d secondes\" %(score, te-ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation croisée sur les paramètres du réseau de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts = time.time()\n",
    "param_grid=[{\"batch_size\":[25,40]}]\n",
    "nnet=GridSearchCV(KerasRegressor(build_fn=baseline_model, verbose=1),param_grid,cv=5,n_jobs=-1)\n",
    "nnet.fit(X_train,Y_train, epochs=1)\n",
    "score = nnet.score(X_test, Y_test)\n",
    "ypred = nnet.predict(X_test)\n",
    "te = time.time()\n",
    "t_total = te-ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nnet.best_params_[\"nb_epoch\"]\n",
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" % (nnet.best_score_,nnet.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autres essais "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "117180/117180 [==============================] - 9s - loss: 2.3663     \n",
      "Epoch 2/30\n",
      "117180/117180 [==============================] - 9s - loss: 1.4698     \n",
      "Epoch 3/30\n",
      "117180/117180 [==============================] - 11s - loss: 1.3754    \n",
      "Epoch 4/30\n",
      "117180/117180 [==============================] - 11s - loss: 1.3098    \n",
      "Epoch 5/30\n",
      "117180/117180 [==============================] - 12s - loss: 1.2721    \n",
      "Epoch 6/30\n",
      "117180/117180 [==============================] - 11s - loss: 1.2337    \n",
      "Epoch 7/30\n",
      "117180/117180 [==============================] - 12s - loss: 1.2123    \n",
      "Epoch 8/30\n",
      "117180/117180 [==============================] - 11s - loss: 1.1909    \n",
      "Epoch 9/30\n",
      "117180/117180 [==============================] - 11s - loss: 1.1712    \n",
      "Epoch 10/30\n",
      "117180/117180 [==============================] - 12s - loss: 1.1469    \n",
      "Epoch 11/30\n",
      "117180/117180 [==============================] - 12s - loss: 1.1333    \n",
      "Epoch 12/30\n",
      "117180/117180 [==============================] - 12s - loss: 1.1189    \n",
      "Epoch 13/30\n",
      "117180/117180 [==============================] - 13s - loss: 1.1009    \n",
      "Epoch 14/30\n",
      "117180/117180 [==============================] - 13s - loss: 1.0885    \n",
      "Epoch 15/30\n",
      "117180/117180 [==============================] - 13s - loss: 1.0731    \n",
      "Epoch 16/30\n",
      "117180/117180 [==============================] - 13s - loss: 1.0591    \n",
      "Epoch 17/30\n",
      "117180/117180 [==============================] - 13s - loss: 1.0494    \n",
      "Epoch 18/30\n",
      "117180/117180 [==============================] - 13s - loss: 1.0368    \n",
      "Epoch 19/30\n",
      "117180/117180 [==============================] - 12s - loss: 1.0242    \n",
      "Epoch 20/30\n",
      "117180/117180 [==============================] - 15s - loss: 1.0148    \n",
      "Epoch 21/30\n",
      "117180/117180 [==============================] - 15s - loss: 1.0033    \n",
      "Epoch 22/30\n",
      "117180/117180 [==============================] - 15s - loss: 0.9934    \n",
      "Epoch 23/30\n",
      "117180/117180 [==============================] - 15s - loss: 0.9860    \n",
      "Epoch 24/30\n",
      "117180/117180 [==============================] - 14s - loss: 0.9784    \n",
      "Epoch 25/30\n",
      "117180/117180 [==============================] - 16s - loss: 0.9663    \n",
      "Epoch 26/30\n",
      "117180/117180 [==============================] - 15s - loss: 0.9590    \n",
      "Epoch 27/30\n",
      "117180/117180 [==============================] - 14s - loss: 0.9525    \n",
      "Epoch 28/30\n",
      "117180/117180 [==============================] - 14s - loss: 0.9430    \n",
      "Epoch 29/30\n",
      "117180/117180 [==============================] - 13s - loss: 0.9362    \n",
      "Epoch 30/30\n",
      "117180/117180 [==============================] - 13s - loss: 0.9294    \n",
      "28410/29296 [============================>.] - ETA: 0sEpoch 1/30\n",
      "117181/117181 [==============================] - 9s - loss: 2.3904     \n",
      "Epoch 2/30\n",
      "117181/117181 [==============================] - 11s - loss: 1.4572    \n",
      "Epoch 3/30\n",
      "117181/117181 [==============================] - 11s - loss: 1.3718    \n",
      "Epoch 4/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.3165    \n",
      "Epoch 5/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.2776    \n",
      "Epoch 6/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.2476    \n",
      "Epoch 7/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.2198    \n",
      "Epoch 8/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.1928    \n",
      "Epoch 9/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.1744    \n",
      "Epoch 10/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.1473    \n",
      "Epoch 11/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.1338    \n",
      "Epoch 12/30\n",
      "117181/117181 [==============================] - 13s - loss: 1.1113    \n",
      "Epoch 13/30\n",
      "117181/117181 [==============================] - 13s - loss: 1.0985    \n",
      "Epoch 14/30\n",
      "117181/117181 [==============================] - 15s - loss: 1.0890    \n",
      "Epoch 15/30\n",
      "117181/117181 [==============================] - 15s - loss: 1.0751    \n",
      "Epoch 16/30\n",
      "117181/117181 [==============================] - 15s - loss: 1.0585    \n",
      "Epoch 17/30\n",
      "117181/117181 [==============================] - 15s - loss: 1.0476    \n",
      "Epoch 18/30\n",
      "117181/117181 [==============================] - 16s - loss: 1.0361    \n",
      "Epoch 19/30\n",
      "117181/117181 [==============================] - 16s - loss: 1.0239    \n",
      "Epoch 20/30\n",
      "117181/117181 [==============================] - 16s - loss: 1.0146    \n",
      "Epoch 21/30\n",
      "117181/117181 [==============================] - 16s - loss: 1.0086    \n",
      "Epoch 22/30\n",
      "117181/117181 [==============================] - 14s - loss: 0.9954    \n",
      "Epoch 23/30\n",
      "117181/117181 [==============================] - 14s - loss: 0.9907    \n",
      "Epoch 24/30\n",
      "117181/117181 [==============================] - 14s - loss: 0.9794    \n",
      "Epoch 25/30\n",
      "117181/117181 [==============================] - 12s - loss: 0.9734    \n",
      "Epoch 26/30\n",
      "117181/117181 [==============================] - 12s - loss: 0.9618    \n",
      "Epoch 27/30\n",
      "117181/117181 [==============================] - 12s - loss: 0.9573    \n",
      "Epoch 28/30\n",
      "117181/117181 [==============================] - 12s - loss: 0.9521    \n",
      "Epoch 29/30\n",
      "117181/117181 [==============================] - 12s - loss: 0.9462    \n",
      "Epoch 30/30\n",
      "117181/117181 [==============================] - 12s - loss: 0.9376    \n",
      "28575/29295 [============================>.] - ETA: 0sEpoch 1/30\n",
      "117181/117181 [==============================] - 9s - loss: 2.3933     \n",
      "Epoch 2/30\n",
      "117181/117181 [==============================] - 10s - loss: 1.4625    \n",
      "Epoch 3/30\n",
      "117181/117181 [==============================] - 11s - loss: 1.3779    \n",
      "Epoch 4/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.3166    \n",
      "Epoch 5/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.2798    \n",
      "Epoch 6/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.2494    \n",
      "Epoch 7/30\n",
      "117181/117181 [==============================] - 11s - loss: 1.2186    \n",
      "Epoch 8/30\n",
      "117181/117181 [==============================] - 11s - loss: 1.1987    \n",
      "Epoch 9/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.1767    \n",
      "Epoch 10/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.1576    \n",
      "Epoch 11/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.1428    \n",
      "Epoch 12/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.1280    \n",
      "Epoch 13/30\n",
      "117181/117181 [==============================] - 14s - loss: 1.1165    \n",
      "Epoch 14/30\n",
      "117181/117181 [==============================] - 14s - loss: 1.0982    \n",
      "Epoch 15/30\n",
      "117181/117181 [==============================] - 15s - loss: 1.0830    \n",
      "Epoch 16/30\n",
      "117181/117181 [==============================] - 14s - loss: 1.0744    \n",
      "Epoch 17/30\n",
      "117181/117181 [==============================] - 11s - loss: 1.0600    \n",
      "Epoch 18/30\n",
      "117181/117181 [==============================] - 11s - loss: 1.0496    \n",
      "Epoch 19/30\n",
      "117181/117181 [==============================] - 11s - loss: 1.0374    \n",
      "Epoch 20/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.0287    \n",
      "Epoch 21/30\n",
      "117181/117181 [==============================] - 13s - loss: 1.0192    \n",
      "Epoch 22/30\n",
      "117181/117181 [==============================] - 11s - loss: 1.0109    \n",
      "Epoch 23/30\n",
      "117181/117181 [==============================] - 15s - loss: 1.0019    \n",
      "Epoch 24/30\n",
      "117181/117181 [==============================] - 16s - loss: 0.9967    \n",
      "Epoch 25/30\n",
      "117181/117181 [==============================] - 16s - loss: 0.9885    \n",
      "Epoch 26/30\n",
      "117181/117181 [==============================] - 14s - loss: 0.9816    \n",
      "Epoch 27/30\n",
      "117181/117181 [==============================] - 13s - loss: 0.9720    \n",
      "Epoch 28/30\n",
      "117181/117181 [==============================] - 15s - loss: 0.9683    \n",
      "Epoch 29/30\n",
      "117181/117181 [==============================] - 13s - loss: 0.9584    \n",
      "Epoch 30/30\n",
      "117181/117181 [==============================] - 14s - loss: 0.9556    \n",
      "28140/29295 [===========================>..] - ETA: 0sEpoch 1/30\n",
      "117181/117181 [==============================] - 9s - loss: 2.3171     \n",
      "Epoch 2/30\n",
      "117181/117181 [==============================] - 10s - loss: 1.4450    \n",
      "Epoch 3/30\n",
      "117181/117181 [==============================] - 13s - loss: 1.3602    \n",
      "Epoch 4/30\n",
      "117181/117181 [==============================] - 13s - loss: 1.3075    \n",
      "Epoch 5/30\n",
      "117181/117181 [==============================] - 15s - loss: 1.2631    \n",
      "Epoch 6/30\n",
      "117181/117181 [==============================] - 13s - loss: 1.2334    \n",
      "Epoch 7/30\n",
      "117181/117181 [==============================] - 13s - loss: 1.2047    \n",
      "Epoch 8/30\n",
      "117181/117181 [==============================] - 13s - loss: 1.1847    \n",
      "Epoch 9/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.1646    \n",
      "Epoch 10/30\n",
      "117181/117181 [==============================] - 11s - loss: 1.1412    \n",
      "Epoch 11/30\n",
      "117181/117181 [==============================] - 11s - loss: 1.1217    \n",
      "Epoch 12/30\n",
      "117181/117181 [==============================] - 11s - loss: 1.1072    \n",
      "Epoch 13/30\n",
      "117181/117181 [==============================] - 14s - loss: 1.0898    \n",
      "Epoch 14/30\n",
      "117181/117181 [==============================] - 17s - loss: 1.0790    \n",
      "Epoch 15/30\n",
      "117181/117181 [==============================] - 14s - loss: 1.0658    \n",
      "Epoch 16/30\n",
      "117181/117181 [==============================] - 15s - loss: 1.0524    \n",
      "Epoch 17/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.0384    \n",
      "Epoch 18/30\n",
      "117181/117181 [==============================] - 17s - loss: 1.0268    \n",
      "Epoch 19/30\n",
      "117181/117181 [==============================] - 15s - loss: 1.0161    \n",
      "Epoch 20/30\n",
      "117181/117181 [==============================] - 13s - loss: 1.0088    \n",
      "Epoch 21/30\n",
      "117181/117181 [==============================] - 12s - loss: 0.9992    \n",
      "Epoch 22/30\n",
      "117181/117181 [==============================] - 12s - loss: 0.9928    \n",
      "Epoch 23/30\n",
      "117181/117181 [==============================] - 12s - loss: 0.9793    \n",
      "Epoch 24/30\n",
      "117181/117181 [==============================] - 13s - loss: 0.9726    \n",
      "Epoch 25/30\n",
      "117181/117181 [==============================] - 13s - loss: 0.9642    \n",
      "Epoch 26/30\n",
      "117181/117181 [==============================] - 16s - loss: 0.9600    \n",
      "Epoch 27/30\n",
      "117181/117181 [==============================] - 16s - loss: 0.9543    \n",
      "Epoch 28/30\n",
      "117181/117181 [==============================] - 16s - loss: 0.9490    \n",
      "Epoch 29/30\n",
      "117181/117181 [==============================] - 15s - loss: 0.9395    \n",
      "Epoch 30/30\n",
      "117181/117181 [==============================] - 16s - loss: 0.9357    \n",
      "28725/29295 [============================>.] - ETA: 0sEpoch 1/30\n",
      "117181/117181 [==============================] - 9s - loss: 2.3267     \n",
      "Epoch 2/30\n",
      "117181/117181 [==============================] - 9s - loss: 1.4514     \n",
      "Epoch 3/30\n",
      "117181/117181 [==============================] - 10s - loss: 1.3605    \n",
      "Epoch 4/30\n",
      "117181/117181 [==============================] - 11s - loss: 1.3121    \n",
      "Epoch 5/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.2687    \n",
      "Epoch 6/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.2374    \n",
      "Epoch 7/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.2100    \n",
      "Epoch 8/30\n",
      "117181/117181 [==============================] - 13s - loss: 1.1881    \n",
      "Epoch 9/30\n",
      "117181/117181 [==============================] - 14s - loss: 1.1666    \n",
      "Epoch 10/30\n",
      "117181/117181 [==============================] - 15s - loss: 1.1402    \n",
      "Epoch 11/30\n",
      "117181/117181 [==============================] - 14s - loss: 1.1222    \n",
      "Epoch 12/30\n",
      "117181/117181 [==============================] - 12s - loss: 1.1085    \n",
      "Epoch 13/30\n",
      "117181/117181 [==============================] - 15s - loss: 1.0930    \n",
      "Epoch 14/30\n",
      "117181/117181 [==============================] - 16s - loss: 1.0762    \n",
      "Epoch 15/30\n",
      "117181/117181 [==============================] - 16s - loss: 1.0646    \n",
      "Epoch 16/30\n",
      "117181/117181 [==============================] - 16s - loss: 1.0474    \n",
      "Epoch 17/30\n",
      "117181/117181 [==============================] - 15s - loss: 1.0364    \n",
      "Epoch 18/30\n",
      "117181/117181 [==============================] - 15s - loss: 1.0264    \n",
      "Epoch 19/30\n",
      "117181/117181 [==============================] - 14s - loss: 1.0197    \n",
      "Epoch 20/30\n",
      "117181/117181 [==============================] - 13s - loss: 1.0082    \n",
      "Epoch 21/30\n",
      "117181/117181 [==============================] - 16s - loss: 0.9972    \n",
      "Epoch 22/30\n",
      "117181/117181 [==============================] - 17s - loss: 0.9918    \n",
      "Epoch 23/30\n",
      "117181/117181 [==============================] - 16s - loss: 0.9800    \n",
      "Epoch 24/30\n",
      "117181/117181 [==============================] - 16s - loss: 0.9703    \n",
      "Epoch 25/30\n",
      "117181/117181 [==============================] - 16s - loss: 0.9647    \n",
      "Epoch 26/30\n",
      "117181/117181 [==============================] - 17s - loss: 0.9565    \n",
      "Epoch 27/30\n",
      "117181/117181 [==============================] - 15s - loss: 0.9478    \n",
      "Epoch 28/30\n",
      "117181/117181 [==============================] - 12s - loss: 0.9443    \n",
      "Epoch 29/30\n",
      "117181/117181 [==============================] - 13s - loss: 0.9391    \n",
      "Epoch 30/30\n",
      "117181/117181 [==============================] - 13s - loss: 0.9319    \n",
      "29190/29295 [============================>.] - ETA: 0sResults: 1.09 (0.01) MSE ; time running : 2051 secondes\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=5, random_state=seed)\n",
    "\n",
    "ts = time.time()\n",
    "results = cross_val_score(nnet, X_train, Y_train, cv=kfold)\n",
    "te = time.time()\n",
    "\n",
    "print(\"Results: %.2f (%.2f) MSE ; time running : %d secondes\" % (results.mean(), results.std(),te-ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Months converted to int.\n",
      "Dummies added.\n",
      "Date dropped.\n",
      "20595/21168 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'File ./../data_meteo/submission_13dec2017_15h00_rnnkeras.csv generated.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Annex.generate_submission_file(\"submission_13dec2017_15h00_rnnkeras.csv\", nnet, scaler, add_dummies=True, var_dummies=['insee','ddH10_rose4'], \n",
    "                         convert_month2int=True, date_method='drop', fillna_method='zeros' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:GPU]",
   "language": "python",
   "name": "conda-env-GPU-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
