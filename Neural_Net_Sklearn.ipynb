{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Défi Grosses Data 2018 - Réseau de neurones avec scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from os import listdir\n",
    "import imp\n",
    "import Annex\n",
    "imp.reload(Annex)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are addressing your request.\n",
      "Data has been imported. Size: (189280, 85)\n",
      "Train size: 132496, Test size: 56784\n",
      "Data scaled\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,Y_train,Y_test,scaler=Annex.get_data_raw(scale=True, \n",
    "                                                        add_dummies=True,\n",
    "                                                        var_dummies=['insee','ddH10_rose4'],\n",
    "                                                        TrainTestSplit=True,\n",
    "                                                        sz_test=0.3,\n",
    "                                                        impute_method='imputed',\n",
    "                                                        convert_month2int=True,\n",
    "                                                        date_method='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid=[{\"hidden_layer_sizes\":list([(50,),(60,)])}]#(50,),(60,),(70,),(80,),,(120,)\n",
    "nnet= GridSearchCV(MLPRegressor(max_iter=500),param_grid,cv=10,n_jobs=-1)\n",
    "nnetOpt=nnet.fit(X_train, Y_train)\n",
    "# paramètre optimal\n",
    "print(\"Meilleur score = %f, Meilleur paramètre = %s\" % (1. - nnetOpt.best_score_,nnetOpt.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 1.19738789697\n",
      "R2 = 0.969500102132\n"
     ]
    }
   ],
   "source": [
    "# prévision de l'échantillon test\n",
    "Y_pred = nnetOpt.predict(X_test)\n",
    "print(\"MSE =\",mean_squared_error(Y_test,Y_pred))\n",
    "print(\"R2 =\",r2_score(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import pyGPs # Library for Gaussian Processes\n",
    "import sys\n",
    "sys.path.append(\"./libs\")\n",
    "import presentation as pr\n",
    "## Creation Model pyGPs\n",
    "model=pyGPs.GPR()\n",
    "m=pyGPs.mean.Const(0.4)\n",
    "k=pyGPs.cov.RBF(log_ell=-2.5,log_sigma=0)\n",
    "model.setPrior(mean=m,kernel=k)\n",
    "\n",
    "## Momentum\n",
    "mom=[]\n",
    "momentum=0.7\n",
    "start_m=0.5\n",
    "end_m=0.99\n",
    "\n",
    "## Learning Rate\n",
    "l=[]\n",
    "learning_rate=0.5\n",
    "start_lr=-4#1e-6\n",
    "end_lr=-2#5e-4\n",
    "\n",
    "## Nb Nodes\n",
    "nn=[]\n",
    "nb_nodes=0.5\n",
    "start_nn=20\n",
    "end_nn=200\n",
    "\n",
    "sz_space=100\n",
    "\n",
    "v=np.reshape(np.linspace(0,1,sz_space),(sz_space,1))\n",
    "v_mom=np.reshape(np.linspace(0,1,sz_space),(sz_space,1))\n",
    "X1,X2=np.meshgrid(v,v_mom)\n",
    "V=np.concatenate([np.reshape(X1,(sz_space**2,1)),np.reshape(X2,(sz_space**2,1))],axis=1)\n",
    "v=np.reshape(v,(len(v),))\n",
    "\n",
    "nb_div=0\n",
    "best_so_far=np.Inf\n",
    "RMSE=[]\n",
    "for i in range(10):\n",
    "    l=np.append(l,learning_rate)\n",
    "    mom=np.append(mom,momentum)\n",
    "\n",
    "    HP=np.concatenate([np.reshape(l,(len(l),1)),np.reshape(mom,(len(mom),1))],axis=1)\n",
    "    if i>1 and ((np.sum(np.abs(HP[-1,:]-HP[-2,:]))<1e-5 and np.sum(np.abs(HP[-1,:]))>1e-7) or ys2[ind_min]<1.4e-2):\n",
    "        print('MINIMA MIGHT BE FOUND, quitting iteration',i)\n",
    "        print(np.sum(np.abs(HP[-1,:]-HP[-2,:])),HP[-1,:],HP[-2,:])\n",
    "        print('ys2[ind_min]',ys2[ind_min])\n",
    "        break\n",
    "    pr.big_iter(i+1,'Learning rate:%0.2e, Momentum:%0.2f, Best so far:%0.4f'% (10**(learning_rate*(end_lr-start_lr)+start_lr),momentum*(end_m-start_m)+start_m,best_so_far))\n",
    "\n",
    "    ## Evaluation\n",
    "    alpha=10**(learning_rate*(end_lr-start_lr)+start_lr)\n",
    "    beta=momentum*(end_m-start_m)+start_m\n",
    "    mlp=MLPRegressor(max_iter=500,hidden_layer_sizes =(80,),learning_rate='constant',learning_rate_init=alpha,momentum=beta)\n",
    "    nnetOpt=mlp.fit(Xnet_train, Y_train)\n",
    "    Y_pred = nnetOpt.predict(Xnet_test)\n",
    "    score=mean_squared_error(Y_test,Y_pred)\n",
    "    RMSE=np.append(RMSE,score)\n",
    "    if RMSE[-1]<best_so_far:\n",
    "        best_so_far=RMSE[-1]\n",
    "        best_net=mlp\n",
    "        #best_ind=\n",
    "    \n",
    "    ## Gaussian Processes\n",
    "    print(HP,RMSE)\n",
    "    model.getPosterior(HP,RMSE)\n",
    "    # model.optimize(l,Y)\n",
    "    ym,ys2,fm,fs2,lp=model.predict(V)\n",
    "    # print(ym.shape,V.shape)\n",
    "\n",
    "    ## Updates\n",
    "    ind_min=np.argmin(ym-ys2)\n",
    "    learning_rate=V[ind_min,0]\n",
    "    momentum=V[ind_min,1]\n",
    "    print('RMSE',score,', S2:%10.2e'%ys2[ind_min])\n",
    "    ## Plots\n",
    "    \n",
    "\n",
    "## Final Outputs\n",
    "pr.line()\n",
    "print('Last learning rate:',10**(l[-1]*(end_lr-start_lr)+start_lr),'\\nMomentum:',mom[-1]*(end_m-start_m)+start_m)\n",
    "print('Last Result:',score)\n",
    "\n",
    "pr.line()\n",
    "#print('Best result:\\n',best_ind,best_net,best_so_far)\n",
    "HP=HP[:-1,:]\n",
    "print(HP)\n",
    "#plots('log')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp=MLPRegressor(max_iter=500,hidden_layer_sizes =(50,))\n",
    "nnetOpt=mlp.fit(Xnet_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train=Y_train.reshape((len(Y_train),1))\n",
    "Y_test=Y_test.reshape((len(Y_test),1))\n",
    "import sys\n",
    "sys.path.append(\"./libs\")\n",
    "import NNet\n",
    "import imp\n",
    "imp.reload(NNet)\n",
    "n_output=[Y_train.shape[1]]\n",
    "n_hid=[7]\n",
    "n_input=[X_train.shape[1]]\n",
    "\n",
    "type_layer=['logistic','linear']\n",
    "threshold=1e-4\n",
    "max_iter=1000\n",
    "mini_batch_coef=0.1\n",
    "do_early_stopping=False\n",
    "\n",
    "min_training_loss=np.Inf\n",
    "min_val_loss=np.Inf\n",
    "min_test_loss=np.Inf\n",
    "\n",
    "i=0\n",
    "for alpha in [0.35]:#[0.002,0.01,0.05,0.2,1,5]:\n",
    "    for mom in [0.9]:\n",
    "        for wd in [0]:#[0.001,0,1,0.1,10,0.0001]:\n",
    "            for n_hid in [[15]]:#[30,20],,[40,30],[10,15],[20,20]\n",
    "                i=i+1\n",
    "                sizes=np.concatenate([n_input,n_hid,n_output])\n",
    "                print('==================== Test n°',i,' alpha=',alpha,' mom=',mom,' wd=',wd,' struct=',sizes)\n",
    "                [model,losses]=NNet.build_model(X_train.T, Y_train.T, wd, sizes, type_layer, 'least_square',\n",
    "                                                   max_iter, alpha, mom,\n",
    "                                                   do_early_stopping, mini_batch_coef, threshold,\n",
    "                                                   print_info=True,train_test_split=False,\n",
    "                                                   X_test=X_test.T,y_test=Y_test.T)\n",
    "                if losses[0]<min_training_loss:\n",
    "                    min_training_loss=losses[0]\n",
    "                    min_alpha=alpha\n",
    "                    momentum=mom\n",
    "                    wd_t=wd\n",
    "                    n_hid_t=n_hid\n",
    "                if losses[1]<min_val_loss:\n",
    "                    min_val_loss=losses[1]\n",
    "                    min_alpha_val=alpha\n",
    "                    momentum_val=mom\n",
    "                    wd_v=wd\n",
    "                    n_hid_v=n_hid\n",
    "                if losses[2]<min_test_loss:\n",
    "                    min_test_loss=losses[2]\n",
    "                    min_alpha_test=alpha\n",
    "                    momentum_test=mom\n",
    "                    wd_test=wd\n",
    "                    n_hid_test=n_hid\n",
    "                    # best_class_perf=class_perf[2]\n",
    "\n",
    "print(i, ' configurations have been tested' )\n",
    "\n",
    "print('==== Training test')\n",
    "print('Min alpha: ',min_alpha)\n",
    "print('Momentum: ',momentum)\n",
    "print('Min val loss: ',min_training_loss)\n",
    "print('WD: ',wd_t)\n",
    "print('n_hid: ',n_hid_t)\n",
    "\n",
    "print('==== Validation test')\n",
    "print('Min alpha: ',min_alpha_val)\n",
    "print('Momentum: ',momentum_val)\n",
    "print('Min val loss: ',min_val_loss)\n",
    "print('WD: ',wd_v)\n",
    "print('n_hid: ',n_hid_v)\n",
    "\n",
    "print('==== Generalisation test')\n",
    "print('Min alpha: ',min_alpha_test)\n",
    "print('Momentum: ',momentum_test)\n",
    "print('Min val loss: ',min_test_loss)\n",
    "print('WD: ',wd_test)\n",
    "print('n_hid: ',n_hid_test)\n",
    "# print('Classification performance: ',best_class_perf)\n",
    "\n",
    "print('\\nElapsed time:',time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
