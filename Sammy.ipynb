{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Défi Grosses Data 2018 - Réseau de neurones avec scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from os import listdir\n",
    "import imp\n",
    "import Annex\n",
    "imp.reload(Annex)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are addressing your request.\n",
      "Data has been imported. Size: (189280, 31)\n",
      "Months converted to int.\n",
      "Dummies added.\n",
      "Date transformed in week number.\n",
      "26528 data points deleted. 14.02 %\n",
      "Train size: 113926, Test size: 48826\n",
      "Data scaled\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,Y_train,Y_test,X,Y,scaler=Annex.get_data_raw(scale=True, \n",
    "                                                        add_dummies=True,\n",
    "                                                        var_dummies=['insee','ddH10_rose4'],\n",
    "                                                        TrainTestSplit=True,\n",
    "                                                        sz_test=0.3,\n",
    "                                                        impute_method='drop',\n",
    "                                                        convert_month2int=True,\n",
    "                                                        date_method='week_number')#'drop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prévision de l'échantillon test\n",
    "Y_pred = nnetOpt.predict(X_test)\n",
    "print(\"MSE =\",mean_squared_error(Y_test,Y_pred))\n",
    "print(\"R2 =\",r2_score(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Annex.generate_submission_file('submission_test.csv', \n",
    "                         nnetOpt, \n",
    "                         scaler, \n",
    "                         add_dummies=True, \n",
    "                         var_dummies=['insee','ddH10_rose4'], \n",
    "                         convert_month2int=True, \n",
    "                         date_method='week_number', \n",
    "                         fillna_method='zeros' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21168,)\n",
      "(21168,)\n",
      "(21168, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'File ./../data_meteo/submission_combinaison_NN_XGB_1_15Dec2017_13h45.csv generated.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Annex.combine_submission_files('submission_combinaison_NN_XGB_1_15Dec2017_13h45.csv', names=['submission_17nov2017_10h30.csv','submission_XGB_13Dec_20h.csv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Sammy, optimize!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome, I am Sammy Nimizz.\n",
      "May I help you?\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:/Users/Quentin/Documents/Python Scripts/MLOptim\")\n",
    "import Sammy\n",
    "import pickle\n",
    "import os\n",
    "path='./results/Resultats.pickle'\n",
    "if os.path.exists(path):\n",
    "    Resultats=Sammy.Results()#Resultats=pickle.load(open(path, 'rb'))\n",
    "else:\n",
    "    Resultats=Sammy.Results()\n",
    "Resultats.say_hello()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/10\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "Running XGBClassifier with parameters: {'subsample': 1, 'silent': True, 'scale_pos_weight': 1, 'reg_lambda': 1, 'reg_alpha': 0, 'objective': 'multi:softmax', 'nthread': None, 'n_jobs': 4, 'n_estimators': 200, 'min_child_weight': 1, 'max_depth': 6, 'max_delta_step': 0, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1, 'colsample_bylevel': 1, 'booster': 'gbtree', 'base_score': 0.5}\n"
     ]
    }
   ],
   "source": [
    "Resultats.random_start(X_train,Y_train,nb_run=10)\n",
    "f=open('./results/Resultats.pickle', 'wb')\n",
    "pickle.dump(Resultats,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prévision de l'échantillon test\n",
    "Y_pred = nnetOpt.predict(X_test)\n",
    "print(\"MSE =\",mean_squared_error(Y_test,Y_pred))\n",
    "print(\"R2 =\",r2_score(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Results:\n",
      "XGBRegressor:\n",
      "Parameters:\n",
      "{'subsample': 1, 'silent': True, 'scale_pos_weight': 1, 'reg_lambda': 1, 'reg_alpha': 0, 'objective': 'reg:linear', 'nthread': None, 'n_jobs': 4, 'n_estimators': 250, 'min_child_weight': 1, 'max_depth': 12, 'max_delta_step': 0, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1, 'colsample_bylevel': 1, 'booster': 'gbtree', 'base_score': 0.5}\n",
      "CV Score:   9.770e-01\n",
      "\n",
      "XGBRegressor:\n",
      "Parameters:\n",
      "{'subsample': 1, 'silent': True, 'scale_pos_weight': 1, 'reg_lambda': 1, 'reg_alpha': 0, 'objective': 'reg:linear', 'nthread': None, 'n_jobs': 4, 'n_estimators': 200, 'min_child_weight': 1, 'max_depth': 14, 'max_delta_step': 0, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1, 'colsample_bylevel': 1, 'booster': 'gbtree', 'base_score': 0.5}\n",
      "CV Score:   9.767e-01\n",
      "\n",
      "XGBRegressor:\n",
      "Parameters:\n",
      "{'subsample': 1, 'silent': True, 'scale_pos_weight': 1, 'reg_lambda': 1, 'reg_alpha': 0, 'objective': 'reg:linear', 'nthread': None, 'n_jobs': 4, 'n_estimators': 150, 'min_child_weight': 1, 'max_depth': 13, 'max_delta_step': 0, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1, 'colsample_bylevel': 1, 'booster': 'gbtree', 'base_score': 0.5}\n",
      "CV Score:   9.766e-01\n",
      "\n",
      "XGBRegressor:\n",
      "Parameters:\n",
      "{'subsample': 1, 'silent': True, 'scale_pos_weight': 1, 'reg_lambda': 1, 'reg_alpha': 0, 'objective': 'reg:linear', 'nthread': None, 'n_jobs': 4, 'n_estimators': 150, 'min_child_weight': 1, 'max_depth': 12, 'max_delta_step': 0, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1, 'colsample_bylevel': 1, 'booster': 'gbtree', 'base_score': 0.5}\n",
      "CV Score:   9.764e-01\n",
      "\n",
      "XGBRegressor:\n",
      "Parameters:\n",
      "{'subsample': 1, 'silent': True, 'scale_pos_weight': 1, 'reg_lambda': 1, 'reg_alpha': 0, 'objective': 'reg:linear', 'nthread': None, 'n_jobs': 4, 'n_estimators': 200, 'min_child_weight': 1, 'max_depth': 10, 'max_delta_step': 0, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1, 'colsample_bylevel': 1, 'booster': 'gbtree', 'base_score': 0.5}\n",
      "CV Score:   9.760e-01\n",
      "\n",
      "XGBRegressor:\n",
      "Parameters:\n",
      "{'subsample': 1, 'silent': True, 'scale_pos_weight': 1, 'reg_lambda': 1, 'reg_alpha': 0, 'objective': 'reg:linear', 'nthread': None, 'n_jobs': 4, 'n_estimators': 150, 'min_child_weight': 1, 'max_depth': 9, 'max_delta_step': 0, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1, 'colsample_bylevel': 1, 'booster': 'gbtree', 'base_score': 0.5}\n",
      "CV Score:   9.745e-01\n",
      "\n",
      "XGBRegressor:\n",
      "Parameters:\n",
      "{'subsample': 1, 'silent': True, 'scale_pos_weight': 1, 'reg_lambda': 1, 'reg_alpha': 0, 'objective': 'reg:linear', 'nthread': None, 'n_jobs': 4, 'n_estimators': 150, 'min_child_weight': 1, 'max_depth': 8, 'max_delta_step': 0, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1, 'colsample_bylevel': 1, 'booster': 'gbtree', 'base_score': 0.5}\n",
      "CV Score:   9.734e-01\n",
      "\n",
      "XGBRegressor:\n",
      "Parameters:\n",
      "{'subsample': 1, 'silent': True, 'scale_pos_weight': 1, 'reg_lambda': 1, 'reg_alpha': 0, 'objective': 'reg:linear', 'nthread': None, 'n_jobs': 4, 'n_estimators': 200, 'min_child_weight': 1, 'max_depth': 7, 'max_delta_step': 0, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1, 'colsample_bylevel': 1, 'booster': 'gbtree', 'base_score': 0.5}\n",
      "CV Score:   9.727e-01\n",
      "\n",
      "XGBRegressor:\n",
      "Parameters:\n",
      "{'subsample': 1, 'silent': True, 'scale_pos_weight': 1, 'reg_lambda': 1, 'reg_alpha': 0, 'objective': 'reg:linear', 'nthread': None, 'n_jobs': 4, 'n_estimators': 200, 'min_child_weight': 1, 'max_depth': 6, 'max_delta_step': 0, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1, 'colsample_bylevel': 1, 'booster': 'gbtree', 'base_score': 0.5}\n",
      "CV Score:   9.713e-01\n",
      "\n",
      "XGBRegressor:\n",
      "Parameters:\n",
      "{'subsample': 1, 'silent': True, 'scale_pos_weight': 1, 'reg_lambda': 1, 'reg_alpha': 0, 'objective': 'reg:linear', 'nthread': None, 'n_jobs': 4, 'n_estimators': 50, 'min_child_weight': 1, 'max_depth': 5, 'max_delta_step': 0, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1, 'colsample_bylevel': 1, 'booster': 'gbtree', 'base_score': 0.5}\n",
      "CV Score:   9.647e-01\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(Sammy.Results(Resultats.bests(nb=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113926, 39)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing XGBRegressor with parameters: {'subsample': 1, 'silent': True, 'scale_pos_weight': 1, 'reg_lambda': 1, 'reg_alpha': 0, 'objective': 'reg:linear', 'nthread': None, 'n_jobs': 4, 'n_estimators': 250, 'min_child_weight': 1, 'max_depth': 12, 'max_delta_step': 0, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1, 'colsample_bylevel': 1, 'booster': 'gbtree', 'base_score': 0.5}\n",
      "Test Score= 0.863882555807\n",
      "Testing XGBRegressor with parameters: {'subsample': 1, 'silent': True, 'scale_pos_weight': 1, 'reg_lambda': 1, 'reg_alpha': 0, 'objective': 'reg:linear', 'nthread': None, 'n_jobs': 4, 'n_estimators': 200, 'min_child_weight': 1, 'max_depth': 14, 'max_delta_step': 0, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1, 'colsample_bylevel': 1, 'booster': 'gbtree', 'base_score': 0.5}\n",
      "Test Score= 0.880543340992\n",
      "Testing XGBRegressor with parameters: {'subsample': 1, 'silent': True, 'scale_pos_weight': 1, 'reg_lambda': 1, 'reg_alpha': 0, 'objective': 'reg:linear', 'nthread': None, 'n_jobs': 4, 'n_estimators': 150, 'min_child_weight': 1, 'max_depth': 13, 'max_delta_step': 0, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1, 'colsample_bylevel': 1, 'booster': 'gbtree', 'base_score': 0.5}\n",
      "Test Score= 0.887704244049\n",
      "Testing XGBRegressor with parameters: {'subsample': 1, 'silent': True, 'scale_pos_weight': 1, 'reg_lambda': 1, 'reg_alpha': 0, 'objective': 'reg:linear', 'nthread': None, 'n_jobs': 4, 'n_estimators': 150, 'min_child_weight': 1, 'max_depth': 12, 'max_delta_step': 0, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1, 'colsample_bylevel': 1, 'booster': 'gbtree', 'base_score': 0.5}\n",
      "Test Score= 0.886456385928\n",
      "Testing XGBRegressor with parameters: {'subsample': 1, 'silent': True, 'scale_pos_weight': 1, 'reg_lambda': 1, 'reg_alpha': 0, 'objective': 'reg:linear', 'nthread': None, 'n_jobs': 4, 'n_estimators': 200, 'min_child_weight': 1, 'max_depth': 10, 'max_delta_step': 0, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1, 'colsample_bylevel': 1, 'booster': 'gbtree', 'base_score': 0.5}\n",
      "Test Score= 0.904052335821\n"
     ]
    }
   ],
   "source": [
    "Resultats.test(X_train, Y_train, X_test, Y_test, nb_test=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param={'subsample': 1, 'silent': True, 'scale_pos_weight': 1, 'reg_lambda': 1, 'reg_alpha': 0, 'objective': 'reg:linear', 'nthread': None, 'n_jobs': 4, 'n_estimators': 250, 'min_child_weight': 1, 'max_depth': 12, 'max_delta_step': 0, 'learning_rate': 0.1, 'gamma': 0, 'colsample_bytree': 1, 'colsample_bylevel': 1, 'booster': 'gbtree', 'base_score': 0.5}\n",
    "method=XGBRegressor(**param)\n",
    "predictor=method.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.863882555807\n",
      "R2 = 0.977995159473\n"
     ]
    }
   ],
   "source": [
    "Y_pred = predictor.predict(X_test)\n",
    "print(\"MSE =\",mean_squared_error(Y_test,Y_pred))\n",
    "print(\"R2 =\",r2_score(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Months converted to int.\n",
      "Dummies added.\n",
      "Date transformed in week number.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'File ./../data_meteo/submission_XGB_13Dec_20h.csv generated.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Annex.generate_submission_file('submission_XGB_13Dec_20h.csv', \n",
    "                         predictor, \n",
    "                         scaler, \n",
    "                         add_dummies=True, \n",
    "                         var_dummies=['insee','ddH10_rose4'], \n",
    "                         convert_month2int=True, \n",
    "                         date_method='week_number', \n",
    "                         fillna_method='zeros' )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import pyGPs # Library for Gaussian Processes\n",
    "import sys\n",
    "sys.path.append(\"./libs\")\n",
    "import presentation as pr\n",
    "## Creation Model pyGPs\n",
    "model=pyGPs.GPR()\n",
    "m=pyGPs.mean.Const(0.4)\n",
    "k=pyGPs.cov.RBF(log_ell=-2.5,log_sigma=0)\n",
    "model.setPrior(mean=m,kernel=k)\n",
    "\n",
    "## Momentum\n",
    "mom=[]\n",
    "momentum=0.7\n",
    "start_m=0.5\n",
    "end_m=0.99\n",
    "\n",
    "## Learning Rate\n",
    "l=[]\n",
    "learning_rate=0.5\n",
    "start_lr=-4#1e-6\n",
    "end_lr=-2#5e-4\n",
    "\n",
    "## Nb Nodes\n",
    "nn=[]\n",
    "nb_nodes=0.5\n",
    "start_nn=20\n",
    "end_nn=200\n",
    "\n",
    "sz_space=100\n",
    "\n",
    "v=np.reshape(np.linspace(0,1,sz_space),(sz_space,1))\n",
    "v_mom=np.reshape(np.linspace(0,1,sz_space),(sz_space,1))\n",
    "X1,X2=np.meshgrid(v,v_mom)\n",
    "V=np.concatenate([np.reshape(X1,(sz_space**2,1)),np.reshape(X2,(sz_space**2,1))],axis=1)\n",
    "v=np.reshape(v,(len(v),))\n",
    "\n",
    "nb_div=0\n",
    "best_so_far=np.Inf\n",
    "RMSE=[]\n",
    "for i in range(10):\n",
    "    l=np.append(l,learning_rate)\n",
    "    mom=np.append(mom,momentum)\n",
    "\n",
    "    HP=np.concatenate([np.reshape(l,(len(l),1)),np.reshape(mom,(len(mom),1))],axis=1)\n",
    "    if i>1 and ((np.sum(np.abs(HP[-1,:]-HP[-2,:]))<1e-5 and np.sum(np.abs(HP[-1,:]))>1e-7) or ys2[ind_min]<1.4e-2):\n",
    "        print('MINIMA MIGHT BE FOUND, quitting iteration',i)\n",
    "        print(np.sum(np.abs(HP[-1,:]-HP[-2,:])),HP[-1,:],HP[-2,:])\n",
    "        print('ys2[ind_min]',ys2[ind_min])\n",
    "        break\n",
    "    pr.big_iter(i+1,'Learning rate:%0.2e, Momentum:%0.2f, Best so far:%0.4f'% (10**(learning_rate*(end_lr-start_lr)+start_lr),momentum*(end_m-start_m)+start_m,best_so_far))\n",
    "\n",
    "    ## Evaluation\n",
    "    alpha=10**(learning_rate*(end_lr-start_lr)+start_lr)\n",
    "    beta=momentum*(end_m-start_m)+start_m\n",
    "    mlp=MLPRegressor(max_iter=500,hidden_layer_sizes =(80,),learning_rate='constant',learning_rate_init=alpha,momentum=beta)\n",
    "    nnetOpt=mlp.fit(Xnet_train, Y_train)\n",
    "    Y_pred = nnetOpt.predict(Xnet_test)\n",
    "    score=mean_squared_error(Y_test,Y_pred)\n",
    "    RMSE=np.append(RMSE,score)\n",
    "    if RMSE[-1]<best_so_far:\n",
    "        best_so_far=RMSE[-1]\n",
    "        best_net=mlp\n",
    "        #best_ind=\n",
    "    \n",
    "    ## Gaussian Processes\n",
    "    print(HP,RMSE)\n",
    "    model.getPosterior(HP,RMSE)\n",
    "    # model.optimize(l,Y)\n",
    "    ym,ys2,fm,fs2,lp=model.predict(V)\n",
    "    # print(ym.shape,V.shape)\n",
    "\n",
    "    ## Updates\n",
    "    ind_min=np.argmin(ym-ys2)\n",
    "    learning_rate=V[ind_min,0]\n",
    "    momentum=V[ind_min,1]\n",
    "    print('RMSE',score,', S2:%10.2e'%ys2[ind_min])\n",
    "    ## Plots\n",
    "    \n",
    "\n",
    "## Final Outputs\n",
    "pr.line()\n",
    "print('Last learning rate:',10**(l[-1]*(end_lr-start_lr)+start_lr),'\\nMomentum:',mom[-1]*(end_m-start_m)+start_m)\n",
    "print('Last Result:',score)\n",
    "\n",
    "pr.line()\n",
    "#print('Best result:\\n',best_ind,best_net,best_so_far)\n",
    "HP=HP[:-1,:]\n",
    "print(HP)\n",
    "#plots('log')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
